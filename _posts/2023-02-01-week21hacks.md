---
title: 5.3-5.4 Computing Bias and Crowd Sourcing
toc: true
comments: true
layout: post
description: Notes and hacks on computing bias and crowd sourcing.
permalink: /CB/bias/crowdsourcing
image: /images/cbimage.png
categories: [week 21, collegeboard, reflection, notes]
---

# 5.3 Bias

## Intentional or Purposeful Bias 
1. 
    - Tik Tok age group: 16-24
    - Facebook age group: 25-34
    - This data proves that different generations are the target audiences for these different apps. I definitely think that these two different companies aim to reach different age groups by putting more trendy content based on age. For an example, I think that Facebook is for a more mature audience with interests more in the adult life such as politics, communication, and community concerns. Tik Tok reaches the younger demographic by promoting trends, dances, and humor that younger people would be more interested in. 
    - This is great for business because business can choose which app to promote on based off of who their target audience and customers are. 

2.  
    - Virtual assistants may have female voices due to past female gender roles. Females previously were associated with helping in the kitchen and the household. Females also have softer voices and may seem more genuine and welcoming to users. Although, many of these devices have an option to switch to a male voice. This may be harmful because women may still be seen as the people who should fulfill tasks in the house instead of males. This may be backtracking the progress that women and men are equal. 
    - I will see promoted videos on Tik Tok that make me want to buy a product or try something new. Instagram, TikTok, and Facebook learn users' interests and direct specific adds/videos/posts for the users to see. This can create intentional biases in users too. 

## HP Computers

- The male in the video does believe that the computer is racist and is intentional. I think this because he comments about how the computer does not track his face due to the color of his skin. This may be true, but he talks about how it is only because he is black, and not considering computer error.
- I think that there was an error with testing when it comes to this bias. The computer has learned how to recognize faces of the lighter colors, but not darker faces. If HP would have tested this feature with various skin colors, they could have caught this error and tried to fix it. 
- I believe that this error was an accident, but is still harmful. People of darker skin color may feel excluded intentionally, even if it was an accident. This should definitely be fixed so all users can use the feature. To produce a better outcome, testing should be done on various, different skin colors and of different groups. 


## Conclusion

When writing algorithms, bias needs to be taken in account when designing and testing algorithms. As developers, we need to test with many different groups and many different biases to get the best feedback that can be used to fix the algorithm to best suit all users.


# 5.4 Crowdsourcing
 

1. A crowdsource idea that can be conducted in the APCSP environment may include a mental health survey for a website. This survey could be sent to the APCSP slack for everyone to fill out. This data would include student opinions from all the different APCSP classes and periods, and not just my APCSP class/period if I were to go around in my class. This use of crowdsourcing will reach a much wider group of students with different experiences, opinions, and biases.

2. Del Norte crowdsourcing would reach an even larger group/demographic of students. This use of crowdsourcing would reach numerous groups of people with different biases and experiences. This would reach more than just the computer science group. Data from this survey would be much more accurate for my project.

3. At N@TM, I could capture data from students and parents walking around. I could ask them about their workout habits and opinions. Doing do would allow me to get data from various age groups and groups of interest. 